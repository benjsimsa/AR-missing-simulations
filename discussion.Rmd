---
title: "Discussion"
output: pdf_document
bibliography: references.bib
---

\newpage

# Discussion

We conducted two Monte Carlo simulation studies to address a knowledge gap about the influence of missing data on the estimation performance of the multilevel autoregressive model. In Simulation A, we only estimated and simulated fixed autoregressive effects (together with both fixed and random intercepts), while in Simulation B, both fixed and random autoregressive effects were simulated and estimated. Three outcomes were evaluated in both simulations: the estimation bias, standard error of the simulations, and statistical power. Four values of compliance and four missingness patterns (data MCAR, data missing in a block of consecutive observations, the highest values missing, and the highest and lowest values missing) were varied across the simulations. The other manipulated factors included the number of participants, number of timepoints per participant, the simulated value of the fixed AR effect, and the variance of the random AR effects.

The two variables related to missing data (compliance and missingness type) emerged as very important factors influencing all three outcomes. In both simulations, missingness type and compliance (and the interaction between the two) were the factors with the largest effect on the bias in the estimation of the fixed AR effect. Similarly, both missingness type and compliance had a strong influence on the statistical power to detect the fixed AR effect in both simulations. With regards to the standard error of the simulations, compliance was found to have a very large effect (more so in Simulation A than Simulation B), while the effect of missingness type was only moderate.

Our results corroborate the conclusions about the importance of the number of timepoints per participant for precise estimation of the autoregressive effects [@hamaker2015; @krone2016]. In general, the estimation bias became considerably less severe as the ESM time-series length per participant increased. *T.obs* also had a large effect on statistical power. However, our simulations show that the context of missingness matters: when the compliance is low and the data are missing MCAR or in blocks, the underestimation of the fixed AR effect caused by the missing data (and the negative consequences for statistical power) gets less severe very quickly as *T.obs* increases. On the other hand, when the missingness is dependent on the value of the process itself (i. e., the most extreme observations are missing), increasing compliance appears to be more important for estimation precision and statistical power than the length of the time-series.

While Krone [@krone2016] found that estimation bias becomes smaller as the simulated fixed AR effect becomes larger, we found an opposite pattern: estimation bias was larger as the simulated fixed AR effect became larger.

Overall, there was always some degree of estimation bias present in the analyses, ranging from very severe (when *T.obs* and compliance were low, and the missingness of data was dependent on the process value) to mild (when compliance was high and the data were missing either MCAR or in block). This bias in estimation might be one of the driving forces behind the low value added by estimates of emotional inertia to the prediction of psychopathology and wellbeing, pointed out by Dejonckheere et al. [-@dejonckheere2019]. Additionally, while the simulation studies did not explicitly assess the bias in the estimation of individual autoregressive effects, the results suggest that some individual differences in inertia estimates might not be caused by real differences in inertia, but due to the bias caused by missingness: for two individual participants with an identical real autoregressive parameter but different compliance and missingness patterns, the inertia estimates can vary considerably.

Our results have several implications for the design psychological research using the multilevel autoregressive model to estimate emotional inertia. First, in line with previous simulation studies, we recommend for researchers to focus on increasing *T.obs* rather than N in order to increase the statistical power and the precision of the inertia estimates. In other words, for optimal statistical performance, it is more effective to make the data collection period longer (or schedule more beeps per day) than to collect data from more participants. According to a recent meta-analysis, Secondly, while the time-series length is very important, researchers should aim to design their ESM studies in a way that will make compliance as high as possible. In line with the evidence about compliance in ESM studies, these design choices include providing financial incentives to participants [@wrzus2022] and making the individual ESM questionnaires shorter [@eisele2020]. Furthermore, the results suggest that the potential presence of missing data should be accounted for in power analyses for ESM studies. In an ideal case, a researcher should have an idea about what the average compliance in their study could be an what missingness patterns might be present in the data. Of course, is not entirely feasible, as it might be difficult to estimate the average compliance, and real-life ESM data will likely include a mixture of different missing data patterns, both at the within- and between-person level. Still, to avoid overestimating statistical power for planned studies, it is advisable to include several different missing data scenarios in the power simulations as a sensitivity check.

## Limitations

First, while the two simulation studies include a wide range of scenarios and parameter combinations, our results are far from comprehensive, and they largely depend on the simulation parameters that were not varied. However, the reproducible code available in the GitHub repository (<https://github.com/benjsimsa/AR-missing-simulations>) provide a sufficient framework for an interested reader to rerun the analyses with different parameters and modify the code to better fit the pecularities of their own study sample and research questions.

Furthermore, the results depend on several assumptions, which were problematised as too simplified in previous studies. We assumed that the innovation variance $\sigma$ was identical for all the participants, and that the random intercepts (and random slopes in Simulation B) came from a normal distribution. We only focused on normally distributed affective processes. While a normal distribution can be assumed for ESM measures of positive emotions, negative affective processes are usually heavily right-skewed in the general population [@haslbeck2022]. Additionally, we assumed that the analysed ESM time-series are measured without any error; however, recent evidence shows that this is very often not the case in real-world research [@dejonckheere2022; @schuurman2019], and unreliability can lead to further attenuation of the estimated parameters [@wenzel2022]. While person-mean centering was carried out using observed means in the simulations we conducted, different ways of person-mean centering, such as using latent person-means, might be more appropriate [@gistelinck2021].

Finally, although I took steps to make the simulations reproducible by making all code and results publicly available, using R packages *here* and *renv*, and reporting the sessionInfo for every simulation, quite a large number of packages with many dependencies were used, which might be detrimental to reproducibility.
